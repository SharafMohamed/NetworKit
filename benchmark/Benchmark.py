"""
The NetworKit benchmark

This module implements a comprehensive benchmark of NetworKit's analytics algorithms



"""


import pandas
import sys
import warnings
import math
import os
import numpy
import matplotlib.pyplot as plt
import seaborn
from time import gmtime, strftime
import signal


import networkit

from util import *
import nk

try:
	import networkx
	import nx
except ImportError as ex:
	print("networkx not available")

try:
	import igraph
	import ig
except ImportError as ex:
	print("igraph not available")
try:
	import graph_tool
	import gt
except ImportError as ex:
	print("graph_tool not available")


# helper function


def averageRuns(df, groupby=["graph"]):
	""" Average running time, modularity, edges per second and number of clusters over multiple runs"""
	df = df.groupby(groupby, as_index=False).mean()
	df = df.sort("m", ascending=True)	# sort by graph size
	return df


def graphMeta(graphNames, graphDir, fileEnding=".gml.graph", graphFormat=networkit.Format.GML):
	meta = []
	for name in graphNames:
		info("loading {name}".format(**locals()))
		G = networkit.readGraph(os.path.join(graphDir, "{0}{1}".format(name, fileEnding)), graphFormat)
		(n, m) = G.size()
		meta.append({"name" : name, "n" : n, "m" : m})
	info("done")
	return pandas.DataFrame(meta, columns=["name", "n", "m"])





def saveData(df, name):
	df.to_csv(os.path.join(bench.dataPath, "{0}.csv".format(name)), sep="\t")

# timeout

class Timeout(Exception):
	pass

def timeoutHandler(signum, frame):
	error("timeout")
	raise Timeout()




class bFail:
	name = "Fail"

	def run(self, G):
		raise Exception("FAIL!")




# Plots

## plot settings

seaborn.set_style("whitegrid")

### Colors
lightred = seaborn.xkcd_rgb["red"]
darkred = seaborn.xkcd_rgb["crimson"]
green = seaborn.xkcd_rgb["teal"]
orange = seaborn.xkcd_rgb["bright orange"]

# plot functions

def timePlot(data, size=(6,3)):
	pos = numpy.arange(len(data))+.5	# the bar centers on the y axis
	labels = list(data["graph"])
	plt.figure(figsize=size)
	plt.xscale("symlog")
	plt.barh(pos, data["time"], align='center', height=0.25, color=lightred)	# notice the 'height' argument
	plt.yticks(pos, labels)
	plt.gca().xaxis.set_minor_locator(plt.LogLocator(subs=[0,1,2,3,4,5,6,7,8,9,10]))
	#gca().xaxis.set_minor_formatter(FormatStrFormatter("%.2f"))
	plt.xlabel("time [s]")
	plt.grid(True)


def epsPlot(data, size=(6,3)):
	pos = numpy.arange(len(data))+.5	# the bar centers on the y axis
	labels = list(data["graph"])
	plt.figure(figsize=size)
	plt.xscale("log")
	plt.barh(pos, data["edges/s"], align='center', height=0.25, color=green)	# notice the 'height' argument
	plt.yticks(pos, labels)
	plt.gca().xaxis.set_minor_locator(plt.LogLocator(subs=[0,1,2,3,4,5,6,7,8,9,10]))
	#gca().xaxis.set_minor_formatter(FormatStrFormatter("%.2f"))
	plt.xlabel("edges / s")
	plt.grid(True)



def graphPlot(data, size=None):
	pos = arange(len(data))	# the bar centers on the y axis
	plt.figure(figsize=(5,3.3))
	sizes = data["m"]
	labels = list(data["graph"])
	#barh(pos, data["n"], log=True, align='center', height=0.4, color="darkgrey")	# notice the 'height' argument
	plt.barh(pos, sizes, log=True, align='center', height=0.4, color="lightblue", label="m")	# notice the 'height' argument
	plt.yticks(pos, labels)
	plt.xlabel("number of edges")
	plt.grid(True)


def barPlot(data, labels, x_label="", y_label="", size=None, color="b", transparency=1.0, scale="linear"):
	pos = numpy.arange(len(data))+.5	# the bar centers on the y axis
	plt.figure(figsize=size)
	plt.xscale(scale)
	plt.barh(pos, data, align='center', height=0.25, color=color, alpha=transparency)	# notice the 'height' argumen
	plt.yticks(pos, labels)
	plt.xlabel(x_label)
	plt.ylabel(y_label)
	plt.grid(True)


class Bench:

	"""
	A Bench objects represents a benchmarking session. It is responsible
	for running the benchmarks, collecting and storing the resulting data.

	"""

	def __init__(self, graphDir, defaultGraphs, outDir, save=True, nRuns=5, cacheGraphs=False, timeout=None, fileEnding="gml.graph", graphFormat=networkit.Format.GML, indexEdges=False):
		self.graphFormat = graphFormat
		self.indexEdges = indexEdges
		self.fileEnding = fileEnding
		self.defaultGraphs = defaultGraphs
		self.nRuns = nRuns  # default number of runs for each algo
		self.graphDir = graphDir
		# store result data of benchmarks
		self.data = []  # list of dictionaries (rows) with keys representing table columns
		self.loadTimes = []
		self.outDir = outDir
		self.save = save  # store data frames on disk if true
		# create output directory if it does not exist
		if self.save:
			if not os.path.isdir(self.outDir):
				os.mkdir(self.outDir)
			self.outDataDir = os.path.join(self.outDir, "data")
			self.plotDir = os.path.join(self.outDir, "plots")
			if not os.path.isdir(self.outDataDir):
				os.mkdir(self.outDataDir)
			if not os.path.isdir(self.plotDir):
				os.mkdir(self.plotDir)
			# log file
			self.logPath = os.path.join(self.outDir, "log.txt")
		# graph cache
		self.cacheGraphs = cacheGraphs
		self.graphCache = {}
		#timeout
		self.timeout = timeout

	def getGraph(self, graphName, algo):
		"""" Get the graph from disk or from in-memory cache"""
		key = algo.framework + graphName
		if key in self.graphCache:
			self.info("getting {0} from cache".format(graphName))
			G = self.graphCache[key]
			return G
		else:
			graphPath = os.path.join(self.graphDir, "{0}.{1}".format(graphName, self.fileEnding))
			self.info("loading {0} from {1}".format(graphName, graphPath))
			with Timer() as t:
				G = algo.loadGraph(graphPath, self.graphFormat)
				if self.indexEdges:
					G.indexEdges()
			self.info("\t took {1} s".format(graphName, t.elapsed))
			eps = self.getSize(G)[1] / t.elapsed
			self.loadTimes.append({"framework" : algo.framework, "graph" : graphName, "time": t.elapsed, "edges/s": eps})
			if self.cacheGraphs:
				self.graphCache[key] = G
			return G

	def getSize(self, G):
		if isinstance(G, networkit.Graph):
			return G.size()
		elif isinstance(G, igraph.Graph):
			return (G.vcount(), G.ecount())
		elif isinstance(G, graph_tool.Graph):
			return (G.num_vertices(), G.num_edges())
		else:
			raise NotImplementedError("cannot get graph size - unknown object type")

	def clearCache(self):
		""" Delete all stored graphs to free memory """
		del self.graphCache
		self.graphCache = {}

	def algoBenchmark(self, algo, graphs=None, nRuns=None, timeout=None):
		""" Run a kernel represented by an algorithm benchmark object """
		# set the defaults
		if nRuns is None:
			nRuns = self.nRuns  # lets argument override the default nRuns
		if graphs is None:
			graphs = self.defaultGraphs
		if timeout is None:
			timeout = self.timeout

		self.info("benchmarking {algo.name}".format(**locals()))
		#table = []  # list of dictionaries, to be converted to a DataFrame

		for graphName in graphs:
			try:
				G = self.getGraph(graphName, algo)
				(n, m) = self.getSize(G)
				try:
					self.info("running {algo.name} ({algo.framework}) {nRuns}x on {graphName}".format(**locals()))
					for i in range(nRuns):
						row = {}	# benchmark data row
						row["algorithm"] = algo.name
						row["framework"] = algo.framework
						row["graph"] = graphName
						row["m"] = m
						try: # timeout
							if timeout:
								signal.signal(signal.SIGALRM, timeoutHandler)
								signal.alarm(int(timeout * 60))  # timeout in seconds
							with Timer() as t:
								result = algo.run(G)
							self.info("\t took {0} s".format(t.elapsed))
							# store data
							row["time"] = t.elapsed
							row["edges/s"] =  m / t.elapsed  # calculate edges per second
							row["result"] = result
						except Timeout as tx:
							self.error("{algo.name} timed out after {timeout} minutes".format(**locals()))
							row["time"] = None
							row["edges/s"] = None
							row["result"] = None
						finally:
							self.data.append(row)
							signal.alarm(int(1e9))	# in any case, cancel the timeout alarm by setting it to a ridiculously high time
				except Exception as ex:
					self.error("algorithm {algo.name} failed with exception: {ex}".format(**locals()))
			except Exception as ex:
				self.error("loading graph {graphName} failed with exception: {ex}".format(**locals()))

		#df = pandas.DataFrame(table)
		#df.sort("m")	# sort by number of edges
		#self.data[algo.name] = df
		# store data frame on disk
		#if self.save:
		#	df.to_csv(os.path.join(self.outDataDir, "{algo.name}.csv".format(**locals())))
		self.log("Done")


	def log(self, message):
		""" Write a message to the logfile"""
		with open(self.logPath, "a") as logfile:
			logfile.write("{0}: {1}\n".format(strftime("%Y-%m-%d %H:%M:%S", gmtime()), message))

	def info(self, message):
		print(message)
		sys.stdout.flush()
		self.log(message)

	def error(self, message):
		print(message)
		sys.stdout.flush()
		self.log(message)

	def debug(self, message):
		pass
		# print(message)


	def timePlot(self, algoName):
		timePlot(averageRuns(self.data[algoName]))
		if self.save:
			plt.savefig(os.path.join(self.plotDir, "{algoName}-time.pdf".format(**locals())), bbox_inches="tight")

	def epsPlot(self, algoName):
		epsPlot(averageRuns(self.data[algoName]))
		if self.save:
			plt.savefig(os.path.join(self.plotDir, "{algoName}-eps.pdf".format(**locals())), bbox_inches="tight")

	def graphPlot(self):
		epsPlot(averageRuns(self.data))
		if self.save:
			plt.savefig(os.path.join(self.plotDir, "graphs.pdf".format(**locals())), bbox_inches="tight")

	def plot(self, algoName):
		print(algoName)
		self.timePlot(algoName)
		self.epsPlot(algoName)

	def finalize(self):
		self.dataFrame = pandas.DataFrame(self.data)
		if self.save:
			self.dataFrame.to_csv(os.path.join(self.outDataDir, "data.csv".format(**locals())))

	def plotSummary2(self, figsize=None, groupby="framework", palette="Greens_d"):
		""" Plot a summary of algorithm performances"""
		if figsize:
			plt.figure(figsize=figsize)
		plt.gca().xaxis.get_major_formatter().set_powerlimits((3, 3))
		plt.xscale("log")
		plt.xlabel("edges/s")
		ax = seaborn.boxplot(y="algorithm", x="edges/s", hue=groupby, data=self.dataFrame, linewidth=1, width=.5, palette=palette)
		if self.save:
			plt.savefig(os.path.join(self.plotDir, "epsSummary.pdf".format(**locals())), bbox_inches="tight")

	def plotSummary(self, algoNames=None, figsize=None):
		""" Plot a summary of algorithm performances"""
		if algoNames is None:
			algoNames = list(self.data.keys())
		epsSummary = pandas.DataFrame()
		for (algoName, algoData) in self.data.items():
			if algoName in algoNames:
				epsSummary[algoName] = pandas.Series(self.data[algoName]["edges/s"])

		# data frame
		self.epsSummary = epsSummary
		self.epsSummary = self.epsSummary.reindex_axis(sorted(self.epsSummary.columns), axis=1)
		if self.save:
			self.epsSummary.to_csv(os.path.join(self.outDataDir, "epsSummary.csv".format(**locals())))
		# plot
		if figsize:
			plt.figure(figsize=figsize)
		plt.gca().xaxis.get_major_formatter().set_powerlimits((3, 3))
		plt.xscale("log")
		plt.xlabel("edges/s")
		seaborn.boxplot(self.epsSummary, order=self.epsSummary.columns, linewidth=1.5, width=.25, color=green, vert=False)
		if self.save:
			plt.savefig(os.path.join(self.plotDir, "epsSummary.pdf".format(**locals())), bbox_inches="tight")

	def plotAll(self):
		for key in self.data.keys():
			self.plot(key)


	def getLoadTimes(self):
		""" Get input times for graphs"""
		return pandas.DataFrame(self.loadTimes)



	def generatorBenchmark(self, generator, argtuples, nRuns=None, timeout=None):
		""" Run a kernel represented by an algorithm benchmark object """
		# set the defaults
		if nRuns is None:
			nRuns = self.nRuns  # lets argument override the default nRuns
		if timeout is None:
			timeout = self.timeout

		genName = str(generator)

		self.info("benchmarking {genName}".format(**locals()))
		table = []  # list of dictionaries, to be converted to a DataFrame

		for param in argtuples:
			try:
				gen = generator(*param)
				row = {}	# benchmark data row
				row["graph"] = str(param)
				try:
					self.info("running {genName} {nRuns} times".format(**locals()))
					for i in range(nRuns):
						row["algorithm"] = genName
						try: # timeout
							result = None
							if timeout:
								signal.signal(signal.SIGALRM, timeoutHandler)
								signal.alarm(int(timeout * 60))  # timeout in seconds
							with Timer() as t:
								result = gen.generate()
							self.debug("took {0} s".format(t.elapsed))
							# store data
							row["m"] = result.numberOfNodes()
							row["time"] = t.elapsed
							row["result"] = result
						except Timeout as tx:
							self.error("{genName} timed out after {timeout} minutes".format(**locals()))
							row["time"] = None
							row["result"] = None
						finally:
							table.append(row)
							signal.alarm(int(1e9))	# in any case, cancel the timeout alarm by setting it to a ridiculously high time
				except Exception as ex:
					self.error("generator {genName} failed with exception: {ex}".format(**locals()))
			except Exception as ex:
				self.error("initializing generator {genName} failed with exception: {ex}".format(**locals()))

		df = pandas.DataFrame(table)
		self.data[genName] = df
		# store data frame on disk
		if self.save:
			df.to_csv(os.path.join(self.outDataDir, "{genName}.csv".format(**locals())))



# - generators
# 	- Erdös-Renyi (generators.ErdosRenyiGenerator)
# 	- Barabasi-Albert (generators.BarabasiAlbertGenerator)
# 	- Chung-Lu (generators.ChungLuGenerator)
# 	- RMAT (generators.RmatGenerator)
